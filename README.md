# AGI-Fun
Fun with training AI models. Uploaded some fine-tuning files I'm playing around for LLMs.


## Citation
The Potemkin benchmark training was inspired by the paper "[Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)"
@article{mancoridis2025potemkin,
  title={Potemkin Understanding in Large Language Models},
  author={Mancoridis, Marina and Weeks, Bec and Vafa, Keyon and Mullainathan, Sendhil},
  journal={arXiv preprint arXiv:2506.21521},
  year={2025}
}
